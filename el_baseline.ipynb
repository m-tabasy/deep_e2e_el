{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "el_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "jKbDUdkw9sAT",
        "mpfjaJPy-fel",
        "O7Gegg82-oFC",
        "iecmhAg3s0Wb",
        "E0hd7jfM-NTh",
        "ohQePvLOm7cq",
        "6vTT6M2799Ed",
        "LQbEnly9BsXV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFDWlKWYvu8M",
        "colab_type": "text"
      },
      "source": [
        "# Entity Linking Baseline on AIDA-YAGO Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKbDUdkw9sAT",
        "colab_type": "text"
      },
      "source": [
        "# 1. Load Libs & Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpfjaJPy-fel",
        "colab_type": "text"
      },
      "source": [
        "## Install Needed Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4rJfvYPzy4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Gegg82-oFC",
        "colab_type": "text"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uoOxX6b-zhL",
        "colab_type": "code",
        "outputId": "777ebc79-2651-468a-e5e9-99123023ebbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "drive_path = 'drive/My Drive/e2e_el/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iecmhAg3s0Wb",
        "colab_type": "text"
      },
      "source": [
        "## Load Pretrained Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY7hKBRIszK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp drive/My\\ Drive/e2e_el/GoogleNews-vectors-negative300.bin.gz word2vec300.bin.gz\n",
        "! gunzip word2vec300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOK0qzuucPUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "vocab_size = 3 * 10**5\n",
        "w2v = KeyedVectors.load_word2vec_format('word2vec300.bin', limit=vocab_size, binary=True)\n",
        "\n",
        "vocab = ['UNK'] + list(w2v.vocab.keys())\n",
        "word2id, id2word = {}, {}\n",
        "\n",
        "for wid, w in enumerate(vocab):\n",
        "  word2id[w] = wid\n",
        "  id2word[wid] = w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cetv4u7AjUAr",
        "colab_type": "code",
        "outputId": "f2855f99-aa9b-4f79-9642-e36f9976f292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "word_vectors = np.zeros((vocab_size + 1, w2v.vector_size))\n",
        "word_vectors[0] = np.zeros((w2v.vector_size,)) # change this to better vec\n",
        "\n",
        "for i in range(1, vocab_size + 1):\n",
        "  word_vectors[i] = w2v[id2word[i]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbW-QdNu8SGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v.similar_by_word('Jobs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0hd7jfM-NTh",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess Wikipedia Dump"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBG2L2aVyN8G",
        "colab_type": "code",
        "outputId": "75093e1d-ccb1-4fdd-9699-a33dae7138fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget https://dumps.wikimedia.org/archive/enwiki/20100312/enwiki-20100312-pages-articles.xml.bz2\n",
        "! cp enwiki-20100312-pages-articles.xml.bz2 drive/My\\ Drive/e2e_el/enwiki.xml.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-15 16:13:12--  https://dumps.wikimedia.org/archive/enwiki/20100312/enwiki-20100312-pages-articles.xml.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.155.106, 2620:0:861:4:208:80:155:106\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.155.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6117881141 (5.7G) [application/octet-stream]\n",
            "Saving to: ‘enwiki-20100312-pages-articles.xml.bz2’\n",
            "\n",
            "enwiki-20100312-pag 100%[===================>]   5.70G  1.97MB/s    in 49m 29s \n",
            "\n",
            "2019-07-15 17:02:42 (1.97 MB/s) - ‘enwiki-20100312-pages-articles.xml.bz2’ saved [6117881141/6117881141]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeqkVDVO_B0F",
        "colab_type": "code",
        "outputId": "65e12d95-f1fc-4bfb-d92c-44e19fd82efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! cp drive/My\\ Drive/e2e_el/enwiki.xml.bz2 enwiki.xml.bz2\n",
        "! bzip2 -dk -v enwiki.xml.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  enwiki.xml.bz2: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHXGyo7Q9KD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python WikiExtractor.py enwiki.xml -o enwiki -l --no_templates --processes 4 -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgU7ahEt9dj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# python 2.7\n",
        "\n",
        "import os\n",
        "\n",
        "def merge(in_dir, out_path):\n",
        "        \n",
        "    with open(out_path, 'w') as out_file:\n",
        "        \n",
        "        for sub_dir in sorted(os.listdir(in_dir)):\n",
        "            print sub_dir, \n",
        "            file_dir = in_dir + '/' + sub_dir\n",
        "            \n",
        "            for in_name in sorted(os.listdir(file_dir)):\n",
        "                with open(file_dir + '/' + in_name, 'r') as in_file:\n",
        "                    for line in in_file:\n",
        "                        out_file.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4bScOIC9egE",
        "colab_type": "code",
        "outputId": "fae6b359-08c9-4de3-c2fd-bcdb6a5a16ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "merge(in_dir='enwiki', out_path='enwiki_full.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AA AB AC AD AE AF AG AH AI AJ AK AL AM AN AO AP AQ AR AS AT AU AV AW AX AY AZ BA BB BC BD BE BF BG BH BI BJ BK BL BM BN BO BP BQ BR BS BT BU BV BW BX BY BZ CA CB CC CD CE CF CG CH CI CJ CK CL CM CN CO CP CQ CR CS CT CU CV CW CX CY CZ DA DB DC DD DE DF DG DH DI DJ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjuwD689VYbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp enwiki_full.txt drive/My\\ Drive/e2e_el/enwiki_links_full.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohQePvLOm7cq",
        "colab_type": "text"
      },
      "source": [
        "## Load Wiki Entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uasf1GvyuxTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('enwiki_full.txt', 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l79NFV2u4HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6c3ade35-f82d-4235-aab5-0662eb7bcc75"
      },
      "source": [
        "print(f.readline() + f.readline() + f.readline() + f.readline() + f.readline() + f.readline())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Anarchism is a <a href=\"political%20philosophy\">political philosophy</a> which considers the <a href=\"Sovereign%20state\">state</a> undesirable, unnecessary and harmful, and instead promotes a stateless society, or <a href=\"anarchy\">anarchy</a>. It seeks to diminish or even abolish authority in the conduct of human relations. Anarchists may widely disagree on what additional criteria are required in anarchism. \"<a href=\"The%20Oxford%20Companion%20to%20Philosophy\">The Oxford Companion to Philosophy</a>\" says, \"there is no single defining position that all anarchists hold, and those considered anarchists at best share a certain family resemblance.\"\n",
            "\n",
            "There are many types and traditions of anarchism, not all of which are mutually exclusive. Strains of anarchism have been divided into the categories of <a href=\"social%20anarchism\">social</a> and <a href=\"individualist%20anarchism\">individualist anarchism</a> or similar dual classifications. Anarchism is often considered to be a radical left-wing ideology, and much of <a href=\"anarchist%20economics\">anarchist economics</a> and <a href=\"anarchist%20law\">anarchist legal philosophy</a> reflect <a href=\"anti-statism\">anti-statist</a> interpretations of <a href=\"anarcho-communism\">communism</a>, <a href=\"collectivist%20anarchism\">collectivism</a>, <a href=\"anarcho-syndicalism\">syndicalism</a> or <a href=\"participatory%20economics\">participatory economics</a>. However, anarchism has always included an individualist strain supporting a <a href=\"market%20economy\">market economy</a> and <a href=\"private%20property\">private property</a>, or unrestrained <a href=\"egoist%20anarchism\">egoism</a> that bases right on might.\n",
            "\n",
            "Others, such as <a href=\"Panarchism\">panarchists</a> and <a href=\"anarchists%20without%20adjectives\">anarchists without adjectives</a>, neither advocate nor object to any particular form of organization as long as it is not compulsory. Differing fundamentally, some <a href=\"anarchist%20schools%20of%20thought\">anarchist schools of thought</a> support anything from extreme <a href=\"individualism\">individualism</a> to complete <a href=\"collectivism\">collectivism</a>. The central tendency of anarchism as a social movement have been represented by communist anarchism, with individualist anarchism being primarily a <a href=\"philosophical%20anarchism\">philosophical or literary phenomenon</a>. Some anarchists fundamentally <a href=\"non-aggression%20principle\">oppose all forms of aggression</a>, supporting <a href=\"self-defense\">self-defense</a> or <a href=\"non-violence\">non-violence</a>, while others have supported the use of some <a href=\"coercion\">coercive</a> measures, including violent <a href=\"revolution\">revolution</a> and <a href=\"terrorism\">terrorism</a>, on the path to an anarchist society.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0z6Xp8kw1Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.corpora import wikicorpus\n",
        "from urllib.parse import unquote"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbj-ZaZ1qEDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp drive/My\\ Drive/e2e_el/enwiki_links_full.txt enwiki_full.txt\n",
        "# ! cp drive/My\\ Drive/e2e_el/entities.pickle entities.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdW2cCOwNIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from importlib import reload\n",
        "\n",
        "sys.path.insert(0, '/content/drive/My Drive/colab_utils/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLOPwwm1ECt4",
        "colab_type": "code",
        "outputId": "0a818002-29f4-4088-9429-e34a179f0093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import process_wiki\n",
        "\n",
        "process_wiki = reload(process_wiki)\n",
        "\n",
        "ent_max = 5500000     # 10 ** 7\n",
        "\n",
        "name2wikiid, wikiid2name, id2wikiid, wikiid2id = process_wiki.load_entity_id_maps(\n",
        "    ent_pickle_path='entites.pickle',\n",
        "    ent_path='enwiki_full.txt',\n",
        "    ent_max=ent_max)\n",
        "\n",
        "ent_size = len(wikiid2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded entities from entites.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03zfyslXLBlk",
        "colab_type": "code",
        "outputId": "485be3f5-b26f-42e6-a580-d7f4de2359b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "list(name2wikiid.keys())[74524:74530]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Locust Grove, Oklahoma',\n",
              " 'Mazie, Oklahoma',\n",
              " 'Murphy, Oklahoma',\n",
              " 'Pensacola, Oklahoma',\n",
              " 'Pin Oak Acres, Oklahoma',\n",
              " 'Pryor Creek, Oklahoma']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQpBBV2iDxlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving maps of entitiy to title words and vice versa\n",
        "\n",
        "wikiid2wordids = {}\n",
        "wid2freq = {}\n",
        "\n",
        "def split_name(name):\n",
        "  name = name.replace(',', '')\n",
        "  name = name.replace('(', '').replace(')', '')\n",
        "  return name.split(' ')\n",
        "\n",
        "for eid, name in wikiid2name.items():\n",
        "  \n",
        "  words = {}\n",
        "  \n",
        "  for word in split_name(name):\n",
        "    \n",
        "    if word not in word2id:\n",
        "      wid = len(word2id)\n",
        "      word2id[word] = wid\n",
        "      id2word[wid] = word\n",
        "    else:\n",
        "      wid = word2id[word]\n",
        "    \n",
        "    if wid in wid2freq:\n",
        "      wid2freq[wid] += 1\n",
        "    else:\n",
        "      wid2freq[wid] = 1\n",
        "    \n",
        "    if word in words:\n",
        "      words[wid] += 1\n",
        "    else:\n",
        "      words[wid] = 1\n",
        "    \n",
        "    wikiid2wordids[eid] = words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVV5ouymw3Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_entity_mentions_map(wiki_path, name2wikiid, wikiid2id):\n",
        "\n",
        "\thyp_pattern = re.compile(r'<a[^>]*href=\\\"([^\\\">]+)\\\"[^>]*>([^>]+)</a>', re.DOTALL | re.UNICODE)\n",
        "\t\n",
        "\tignored_names = set()\n",
        "\twikiid2mentions = {}\n",
        "\t\n",
        "\twith open(wiki_path, 'r', encoding='utf8') as inf:\n",
        "\t\n",
        "\t\tfor line in inf:\n",
        "      \n",
        "      if len(wikiid2mentions) > 100:\n",
        "        return wikiid2mentions\n",
        "\t\t\n",
        "\t\t\tclean_text = wikicorpus.filter_wiki(line)\n",
        "\t\t\thyp_matches = re.finditer(hyp_pattern, line)\n",
        "\n",
        "\n",
        "\t\t\tfor link in hyp_matches:\n",
        "\n",
        "\t\t\t\tname = unquote(link.groups()[0])   # wikipedia url id\n",
        "\t\t\t\tmention = link.groups()[1]\n",
        "\t\t\t\t\n",
        "\t\t\t\tif name in name2wikiid:\n",
        "\t\t\t\t\twikiid = name2wikiid[name]\n",
        "\t\t\t\t\tif wikiid not in wikiid2mentions:\n",
        "\t\t\t\t\t\twikiid2mentions[wikiid] = []\n",
        "\t\t\t\t\twikiid2mentions[wikiid].append(mention)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tignored_names.add(name)\n",
        "\t\n",
        "\treturn wikiid2mentions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw1Z1uqn9Ach",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# vector_size = 300\n",
        "# entity_vectors = np.random.uniform(low=-1, high=1.0,\n",
        "#                                    size=(ent_size+1, vector_size))\n",
        "# entity_vectors = np.memmap('ent2rand300.bin', \n",
        "#                            dtype='float32', mode='w+',\n",
        "#                            shape=(ent_size+1, vector_size))\n",
        "\n",
        "# entity_vectors[0] = np.zeros((vector_size,))   # unk entity\n",
        "\n",
        "# normalize ent vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgupC8y2-UNe",
        "colab_type": "text"
      },
      "source": [
        "## Prepare AIDA-YAGO Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlzcDwp_sTdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp drive/My\\ Drive/e2e_el/aida-yago2-dataset.tsv aida-yago2-dataset.tsv\n",
        "# ! wget http://resources.mpi-inf.mpg.de/yago-naga/aida/download/aida_means.tsv.bz2\n",
        "# ! bzip2 -dk aida_means.tsv.bz2# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3eSweffwPRX",
        "colab_type": "code",
        "outputId": "ddcce7b2-39b2-4063-9786-67e0b13d377c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "import process_aida\n",
        "from importlib import reload\n",
        "\n",
        "sys.path.insert(0, '/content/drive/My Drive/colab_utils/')\n",
        "process_aida = reload(process_aida)\n",
        "\n",
        "process_aida.split_aida(aida_path='aida-yago2-dataset.tsv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aida splitted to aida-train.tsv, aida-testa.tsv, aida-testb.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqSRQvQfPbmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word, wikiid in process_aida.gen_mentions('aida-train.tsv'):\n",
        "  \n",
        "  if word not in word2id:\n",
        "    wid = len(word2id)\n",
        "    word2id[word] = wid\n",
        "    id2word[wid] = word\n",
        "  else:\n",
        "    wid = word2id[word]\n",
        "    \n",
        "  if wid in wid2freq:\n",
        "    wid2freq[wid] += 1\n",
        "  else:\n",
        "    wid2freq[wid] = 1\n",
        "      \n",
        "  if wikiid not in wikiid2wordids:\n",
        "    wikiid2wordids[wikiid] = {}\n",
        "      \n",
        "  if wid in wikiid2wordids[wikiid]:\n",
        "    wikiid2wordids[wikiid][wid] += 1\n",
        "  else:\n",
        "    wikiid2wordids[wikiid][wid] = 1\n",
        "    \n",
        "for _, wordfreqs in wikiid2wordids.items():\n",
        "  for wid in wordfreqs.keys():\n",
        "    wordfreqs[wid] /= wid2freq[wid]\n",
        "    \n",
        "wid2wikiids = {}\n",
        "\n",
        "for wikiid, wordids in wikiid2wordids.items():\n",
        "  for wid in wordids:\n",
        "    if wid not in wid2wikiids:\n",
        "      wid2wikiids[wid] = {}\n",
        "    wid2wikiids[wid][wikiid] = wikiid2wordids[wikiid][wid]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLfuQhwHbhqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def data_from_generator(gen, begin_inside_weight=4):\n",
        "  \n",
        "  data_x, data_y = [], []\n",
        "  data_w = []\n",
        "  lengths = []\n",
        "  \n",
        "  for (x, y) in gen:\n",
        "    lengths.append(len(x))\n",
        "    data_x.append(x)\n",
        "    data_y.append(y)\n",
        "\n",
        "  data_x = pad_sequences(data_x, maxlen=max(lengths), value=0, dtype=np.int32,\n",
        "                         padding='post', truncating='post')\n",
        "  data_y = pad_sequences(data_y, maxlen=max(lengths), value=0, dtype=np.int32,\n",
        "                         padding='post', truncating='post')\n",
        "  \n",
        "  data_w = np.ones(data_y.shape)\n",
        "  data_w[data_y > 0] = begin_inside_weight\n",
        "\n",
        "  data_y = to_categorical(data_y, num_classes=3, dtype=np.int32)\n",
        "  \n",
        "  return data_x, data_y, data_w, max(lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UBbBApcjc0u",
        "colab_type": "code",
        "outputId": "b77b7298-d57e-43f5-8f2b-313e0a1a1dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_gen = process_aida.gen_md_data(aida_path='aida-train.tsv',\n",
        "                                     word2id=word2id)\n",
        "valid_gen = process_aida.gen_md_data(aida_path='aida-testa.tsv',\n",
        "                                     word2id=word2id)\n",
        "\n",
        "train_x, train_y, train_w, max_len_train = data_from_generator(train_gen)\n",
        "valid_x, valid_y, valid_w, max_len_valid = data_from_generator(valid_gen)\n",
        "\n",
        "ys = {0: 158121, 1: 22866, 2: 10484}\n",
        "\n",
        "max_len = max(max_len_train, max_len_valid)\n",
        "print(len(train_x), len(valid_x), max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "946 216 1018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vTT6M2799Ed",
        "colab_type": "text"
      },
      "source": [
        "# 2. Define Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0VF6IMvJRtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "  \n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "      \n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyeAC4AOrgUY",
        "colab_type": "text"
      },
      "source": [
        "## Design & Train Mention Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVO4Edzgy-X0",
        "colab_type": "code",
        "outputId": "f5d6697c-2010-4629-ffc6-505329a5b384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "word_ids = Input(shape=(None,), name='input')\n",
        "x = Embedding(len(word_vectors), output_dim=300, weights=[word_vectors], trainable=False, name='w2v')(word_ids)\n",
        "x = Bidirectional(LSTM(units=300, return_sequences=True, recurrent_dropout=0.1, name='lstm1'))(x)\n",
        "x = Bidirectional(LSTM(units=30, return_sequences=True, recurrent_dropout=0.1, name='lstm2'))(x)\n",
        "output = TimeDistributed(Dense(3, activation='softmax'))(x)\n",
        "\n",
        "model = Model(word_ids, output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              sample_weight_mode='temporal',\n",
        "              metrics=['accuracy', f1])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, None)              0         \n",
            "_________________________________________________________________\n",
            "w2v (Embedding)              (None, None, 300)         90000300  \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, None, 600)         1442400   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, None, 60)          151440    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, None, 3)           183       \n",
            "=================================================================\n",
            "Total params: 91,594,323\n",
            "Trainable params: 1,594,023\n",
            "Non-trainable params: 90,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hswP6hrHK4aX",
        "colab_type": "code",
        "outputId": "df33bec1-c6af-4117-9c18-651cfbe296b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "history = model.fit(x=train_x, y=train_y, sample_weight=train_w,\n",
        "                    validation_data=(valid_x, valid_y, valid_w),\n",
        "                    batch_size=64, epochs=20, verbose=1)\n",
        "\n",
        "model.save('md_model.h5')\n",
        "! cp md_model.h5 drive/My\\ Drive/e2e_el/md_model.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 946 samples, validate on 216 samples\n",
            "Epoch 1/20\n",
            "946/946 [==============================] - 108s 115ms/step - loss: 0.6963 - acc: 0.9404 - f1: 0.6861 - val_loss: 0.3944 - val_acc: 0.9443 - val_f1: 0.9442\n",
            "Epoch 2/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.2825 - acc: 0.9589 - f1: 0.9551 - val_loss: 0.3168 - val_acc: 0.9528 - val_f1: 0.9527\n",
            "Epoch 3/20\n",
            "946/946 [==============================] - 105s 111ms/step - loss: 0.2397 - acc: 0.9599 - f1: 0.9601 - val_loss: 0.2689 - val_acc: 0.9507 - val_f1: 0.9518\n",
            "Epoch 4/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.1954 - acc: 0.9689 - f1: 0.9698 - val_loss: 0.2064 - val_acc: 0.9710 - val_f1: 0.9722\n",
            "Epoch 5/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.1515 - acc: 0.9800 - f1: 0.9803 - val_loss: 0.1588 - val_acc: 0.9808 - val_f1: 0.9808\n",
            "Epoch 6/20\n",
            "946/946 [==============================] - 105s 110ms/step - loss: 0.1221 - acc: 0.9847 - f1: 0.9847 - val_loss: 0.1292 - val_acc: 0.9853 - val_f1: 0.9850\n",
            "Epoch 7/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.1015 - acc: 0.9872 - f1: 0.9871 - val_loss: 0.1079 - val_acc: 0.9879 - val_f1: 0.9878\n",
            "Epoch 8/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.0864 - acc: 0.9887 - f1: 0.9887 - val_loss: 0.0920 - val_acc: 0.9886 - val_f1: 0.9887\n",
            "Epoch 9/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.0754 - acc: 0.9892 - f1: 0.9893 - val_loss: 0.0849 - val_acc: 0.9901 - val_f1: 0.9900\n",
            "Epoch 10/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.0678 - acc: 0.9900 - f1: 0.9901 - val_loss: 0.0811 - val_acc: 0.9847 - val_f1: 0.9848\n",
            "Epoch 11/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.0632 - acc: 0.9898 - f1: 0.9900 - val_loss: 0.0749 - val_acc: 0.9908 - val_f1: 0.9909\n",
            "Epoch 12/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.0590 - acc: 0.9909 - f1: 0.9910 - val_loss: 0.0700 - val_acc: 0.9898 - val_f1: 0.9898\n",
            "Epoch 13/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.0557 - acc: 0.9909 - f1: 0.9910 - val_loss: 0.0680 - val_acc: 0.9901 - val_f1: 0.9902\n",
            "Epoch 14/20\n",
            "946/946 [==============================] - 104s 109ms/step - loss: 0.0525 - acc: 0.9918 - f1: 0.9919 - val_loss: 0.0659 - val_acc: 0.9907 - val_f1: 0.9909\n",
            "Epoch 15/20\n",
            "946/946 [==============================] - 105s 111ms/step - loss: 0.0497 - acc: 0.9921 - f1: 0.9922 - val_loss: 0.0639 - val_acc: 0.9908 - val_f1: 0.9909\n",
            "Epoch 16/20\n",
            "946/946 [==============================] - 104s 110ms/step - loss: 0.0479 - acc: 0.9924 - f1: 0.9924 - val_loss: 0.0626 - val_acc: 0.9903 - val_f1: 0.9905\n",
            "Epoch 17/20\n",
            "946/946 [==============================] - 102s 108ms/step - loss: 0.0467 - acc: 0.9925 - f1: 0.9926 - val_loss: 0.0618 - val_acc: 0.9892 - val_f1: 0.9893\n",
            "Epoch 18/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.0447 - acc: 0.9928 - f1: 0.9929 - val_loss: 0.0599 - val_acc: 0.9911 - val_f1: 0.9912\n",
            "Epoch 19/20\n",
            "946/946 [==============================] - 103s 109ms/step - loss: 0.0429 - acc: 0.9931 - f1: 0.9931 - val_loss: 0.0588 - val_acc: 0.9916 - val_f1: 0.9916\n",
            "Epoch 20/20\n",
            "946/946 [==============================] - 105s 111ms/step - loss: 0.0424 - acc: 0.9930 - f1: 0.9930 - val_loss: 0.0582 - val_acc: 0.9921 - val_f1: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIkW96z8fP5z",
        "colab_type": "code",
        "outputId": "5d67f866-5187-4003-8f9d-c6c640575761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 4\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Loss per epoch')\n",
        "plt.plot(history.history['loss'], 'b.')\n",
        "plt.plot(history.history['val_loss'], 'b-')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('F1 per epoch')\n",
        "plt.plot(history.history['f1'], 'b.')\n",
        "plt.plot(history.history['val_f1'], 'b-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEICAYAAABcYjLsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmclXXd//HXhxkWZREUXEA2FRfM\nfQLHdVRQtFLLtEHz1tLIuyzLlh9Wt3lLaXtZYmVF6p2CRBslBbhMVqIyKGigIhKKgAiiiAKyfX5/\nfK/jXBzOmXPNzFln3s/H43qc61zLuT5zDnznPd/zva7L3B0RERERkY6uU6kLEBEREREpBwrGIiIi\nIiIoGIuIiIiIAArGIiIiIiKAgrGIiIiICKBgLCIiIiICKBiLFJ2ZNZjZlaWuQ0REmpiZm9lBpa5D\nSkvBWBIxs2VmNqrUdYiISOtFbfkmM3srNvWP1t1uZs+Z2Q4zu7zEpYqUhIKxdBhmVl3qGkREysAH\n3L1HbFoZLV8AfAp4opjFmFlVMY8n0hwFY2kzM/uEmS0xs3VmNj3W+2Bm9kMze9XM3jSzp83sPdG6\nc8xskZltMLMVZvbFLK99uZn9y8xuNbP1ZvasmZ0RW7+Hmf3KzFZFr/ONVCMb2/eHZvYacEOG1+9k\nZuPN7AUze83MpprZntG6IdFXa+PMbGV0jC/G9u1qZj+K1q2M5rvG1p9nZvOjn/0FMxsTO/TgqLYN\nZjbLzPq26UMQEWkjd5/o7g8Am3Nta2Z3mNnPzGx21I793cwGx9YfGq1bF/VCX5S270/NbIaZvQ2c\nluH1k7Tt2X4v9I9+F62Lfjd9Irauysy+ErXJG8xsnpkNjB16lJk9b2ZvmNlEM7MWv5FS0RSMpU3M\n7HTgZuAiYD/gRWBKtPpM4BTgYGCPaJvXonW/Aj7p7j2B9wAPNnOYkcALQF/g68DvU+EVuAPYBhwE\nHBMd88q0fZcC+wDfzPDanwHOB04F+gOvAxPTtjkNGBa99v+LDSn5KnA8cDRwFDAC+Fr0vowA7gK+\nBPSO3odlsde8GPgYsDfQBcj4h4GISBm7BJhAaJvnA3cDmFl3YDZwD6GNqwduM7PhsX0vJrTJPYF/\nZnjtO8jdtmf7vTAFeJnQpn8YuCn6XQVwLTAWOAfoBXwc2Bh73fcD7wWOJPzOOivheyHthbtr0pRz\nIoS6URmW/wr4Tux5D2ArMAQ4HVhMCI+d0vZ7Cfgk0CvHcS8HVgIWW/Y4cCkh7L4D7BZbNxZ4KLbv\nSzle/xngjNjz/aL6q6OfwYFDY+u/A/wqmn8BOCe27ixgWTT/c+CHWY7ZAHwt9vxTwN9K/Rlr0qSp\n/U9RW/4W8EY0/THDNv8ELs/xOncAU2LPewDbgYHAR4B/pG3/c+DrsX3vaua1k7Tt2X4vDIzq6Blb\ndzNwRzT/HHBeluM6cFLs+VRgfKk/M03FndRjLG3Vn9BLDIC7v0XoFR7g7g8CtxJ6YF+NTuzoFW16\nAeEv9hejr+BqmznGCo9aqciL0XEHA52BVdHXXm8QGt+9Y9suz1H/YOAPsf2fITSq+2R5jdSxd/nZ\n09YNJATnbF6JzW8k/FIRESmG8929dzSd34bXebdtjNr+dTS1zSNT7WrUtl4C7Jtp3wyStO3Zfi/0\nB9a5+4a0dQOiebXN0iwFY2mrlYRGDHj3K7S9gBUA7v5jdz8OGE4YUvGlaPlcdz+P0ND9kfCXeTYD\n0sZ5DYqOu5zQq9A31sj3cvfDY9vGG85MlgNnx/bv7e7d3H1FbJv4+LPUsXf52dPWLQcOzHFsEZFK\n9m7baGY9gD1papv/ntau9nD3/47t21zbnKRtz/Z7YSWwp5n1TFuXatPVNkuzFIylJTqbWbfYVA1M\nBj5mZkdHJ57dBDzm7svM7L1mNtLMOgNvE07o2GFmXczsEjPbw923Am8CO5o57t7AZ82ss5ldCBwG\nzHD3VcAs4Ptm1is6ke5AMzu1BT/Tz4Bvpk4aMbN+ZnZe2jb/Y2a7m9nhhHHB90bLJwNfi/bpC1wP\n/CZa96vofTkjqmuAmR3agrpERIoqapu7AUZTe99cTjjHzE4ysy6EscaPuvty4C/AwWZ2adRud45+\nHxyWpI6EbXu23wvLgUeAm6P6jwSuoKlt/iUwwcyGWXCkme2V+E2Sdk/BWFpiBrApNt3g7vcD/wP8\nDlhF+Eu8Ptq+F/ALwgltLxKGWHw3WncpsMzM3gSuInzNls1jhJPf1hJO1viwu6dO4vsvwslri6Lj\nTCOME07qFmA6MMvMNgCPEk7qiPs7sAR4APieu8+Kln8DaASeAp4mXOLoGwDu/jghRP8QWB+9xmBE\nRMrXLELbfgJwezR/SjPb30M48W0dcBzwUYBoGMOZhN8FKwnDE74NdM38Mhnlatub+70wlnCOyErg\nD4SxzfdH635A+IZyFqFT5lfAbi2oS9o523mIjkh5sXCR+Svd/aQSHHsI8B+gs7tvK/bxRUTKlZnd\nAbzs7l8rwbEvp0S/F6T9U4+xiIiIiAgKxiIiIiIigIZSiIiIiIgA6jEWEREREQHC3b1Kom/fvj5k\nyJBSHV5EpNXmzZu31t37lbqOYlKbLSKVLGm7XbJgPGTIEBobG0t1eBGRVjOzF3Nv1b6ozRaRSpa0\n3dZQChERERERFIxFRCqSmU0ys1fN7N9Z1puZ/djMlpjZU2Z2bGzdZWb2fDRdVryqRUTKm4KxiEhl\nugMY08z6swl3BhsGjAN+CmBmexLuVjYSGAF83cz6FLRSEZEKoWAsIlKB3P1hwq14szkPuMuDR4He\nZrYfcBYw293XufvrwGyaD9giIh1GomBsZmPM7LnoK7nxGdb/0MzmR9NiM3sj/6WKiEgLDACWx56/\nHC3LtnwXZjbOzBrNrHHNmjUFK1REpFzkvCqFmVUBE4HRhAZ0rplNd/dFqW3c/fOx7T8DHFOAWkVE\npIjc/XbgdoCamhrdDUpE2r0kPcYjgCXuvtTdtwBTCF/RZTMWmJyP4tLNmQM33xweRUSkWSuAgbHn\n+0fLsi0XEUmstZmsLVmuGDkwyXWMM33tNjLThmY2GBgKPJhl/TjCSSAMGjSoRYXOmQNnnAFbtkCX\nLvDAA1Bb26KXEBHpSKYDV5vZFEKbvd7dV5nZTOCm2Al3ZwLXlapIkfZkzhxoaIC6upZnlFLs25b9\nWpPJ2pLlipUD832Dj3pgmrtvz7SyLV/LNTSEN2P79vDY0KBgLCIdl5lNBuqAvmb2MuFKE50B3P1n\nwAzgHGAJsBH4WLRunZlNAOZGL3Wjuzd3Ep9Im7Ul9D38MPz97yEUnXBCcY7Z0n23bw91nnNOU3Cb\nOhXe+96w3ixMqfn0x7lz4YMfbNp35kw4+eSmbXLVWqyQum0brF0LU6bAO+/Ajh3h8Sc/gWXLwvqt\nWzNP27aF93TzZnAPj5/9LAwfHl5jy5amx/h86nHtWti0KdRRyByYJBi35Gu3euDTbS0qk7q68MGl\nPsC6ukIcRUSkMrj72BzrnSztsbtPAiYVoi4pf82Fvs2bYf36pumNN3Z+/uyz8NZbUF8P556b/Hgt\nCWDbt8OTT8Ls2TBtGjzxRFh+/fXQsyfssQd07w49eoQp0/y6dTBpUghj1dXwqU/BwIFNAa25x1Wr\nQjDdvh06dYLjjoOuXcN7kz6980543Lp11/cx6fuTbvNmOPXUMF9VBZ07Nz+tW9cUGDdtgquuguOP\nD+9Dz55hSs3HH6dO3Tnc/uIXsHQprFmTfXr99V3r3bEDJk8OUy6dOoVQDOFx2bIQeLt0Ce9xly5N\n83vssfOy9evD57JjR2FzYJJgPBcYZmZDCYG4Hrg4fSMzOxToAxRk5EdtbfjP1Nq//kRERNqTBx+E\n+++HY4+FQw6BjRvh7bebf3zhBZg+vSn0HXxwmE8F4C1bkh178mTo3x9OPx1OOglOPDH0/HXKcOZS\nkm98X3wxBOFZs8Lv+nXRdxj77ht6Td3D43veA4cdFsL5W2+Fn2v16vBzvf120/Jt25pee+tWuOWW\nXeuqrg5T5847P27cGGqFEMJWr4YDDwyBslu3naeuXZvmV6+GX/6yKYxfcw0ccMDOQTDb43/+AxMn\nhn2rquDjH4f99tu1xzVTT+zq1WHasSO8R+vWhc94w4bwniSxYwf8+tdhglBD377Qr1+Yjj66ab5f\nP9h773DMhQthxIjwx0N6YE+9p/HnnTqVbrhJUjmDsbtvM7OrgZlAFTDJ3Rea2Y1Ao7tPjzatB6ZE\nvRQFUVurQCwiIu2fe+hJe/HFMC1b1jT/4ouhZ2/Dhpa95u67h8d46NuxI4SaPfYIU+/eTfPp06RJ\n8I1vNAWwPn1CmP3Nb8Lr9e4dAvKJJ4awXFMDu+2W+Rvf9evhoYfC/rNnw/PPh9fo3x8+8AEYPRpG\njQo/Z7y3+fvfT5YDHn4Yzjqrab8//jEMw0iFtaqq7MMU0nu4p0xJnj0uvbT1we2ii/IfGHfsCOF4\nw4bwB0P8ccMGWLAgfAswcmT4zFKht3fvzH/k5ENbslwxcqAVMMc2q6amxhsbG0tybBGRtjCzee5e\nU+o6ikltdv5t2gT33BN6SffcM4SYVPB96aXQcxnXsycMHhymtWvh8cebelLr6+GjHw1DCbp3DyE4\n/titW1NvXT5Pfjr++NBb+69/wT//GR6feSZs37lzCMcnnhh6H194IYTyZ5+Fxx4L8927h2EDZ54Z\nwvBhh+0aWIt9Yllb95XylLTdVjAWEWkhBWNpCXd45RWYPz/00C1YEOYXLw5hOKV37/CVfSr8pqYh\nQ8Jj795NobGtAbeQgfG11+CRR5qC8ty5TUM0OnUKYXn06DDV1ob6RQpNwVhEpEAUjCUuHhZrauC5\n53YNwfEbBw4eDEcdFb7SbmgI4bhTpzBM4boWXDivUno1N2+GefNCYD755DAEQ6TYkrbb+b5cm4iI\nSIfxj3+EsbCpqxJUVzfNd+0Khx8exswedVSYjjyyKRim9/q29Cz7Sjnvplu3MJxCpBIoGIuIiLTQ\nc8+FM/hvu23nKzkcfzx88pPhLP5DDglBORtdbUmk/CgYi4iIJPDWW+Har5MmhbGzVVUhzD7+eLiU\nVteu8O1vtyzgVkqvr0hHoWAsIiKShXs4kWzSJLj33nDpq0MOCQH40kvDtWYrZayviOSmYCwiIpJm\n1Sq4664QiBcvDncKq68PN16ord35kmLq9RVpPxSMRURECCfN3XdfCMMzZoTr7J50EowfDxdeGMKx\niLRvCsYiItLhLV4cbm+8YkW4GcWXvgQf+1i4ZbKIdBwFuuGfiIhIZXjsMRgxIoTiTp3CSXbnnqtQ\nLNIRKRiLiEiHNWNG6Cnu1ClMO3aEIRUNDaWuTERKQcFYREQ6pDvuCD3DhxwSTrTr2jVcgq01N9sQ\nkfZBY4xFRKRDcYdvfQu+8pVw57nf/x569dLNNkREwVhERDqQ7dvhc5+DW2+FsWNDr3GXLmGdLrsm\nIhpKISIiHcLmzSEM33orXHst/OY3TaFYRATUYywiIu1ItrvQrV8P558f1n3ve/CFL5SoQBEpawrG\nIiLSLsyZE8YMb9kSeoIfeCCE45Ur4eyzYdGi0Et8ySWlrlREypWCsYiItAsNDSEUb98eHhsaYM89\n4ayz4LXXwl3tzjyz1FWKSDlTMBYRkbKTbUhEc+rqQk9xqse4b1848cRwCbaGBjjuuMLVKyLtg4Kx\niIiUlWxDInKprW265FrnznDNNdC/P8ycCQceWPCyRaQdUDAWEalQZjYGuAWoAn7p7t9KWz8YmAT0\nA9YBH3X3l6N124Gno01fcvdzi1Z4DvfdF64g4R4ef/QjWL0adtsNdt89+2N1dQjHzzwD48bB0UeH\n19pnn1L/RCJSKRIF41yNb7TNRcANgAML3P3iPNYpIiIxZlYFTARGAy8Dc81sursvim32PeAud7/T\nzE4HbgYujdZtcveji1p0M7Zsgb/+NVxX+M9/DqEYwuPUqWHKpbo6BOQ33wxjiadNg549C1q2iLQz\nOYNxksbXzIYB1wEnuvvrZrZ3oQoWEREARgBL3H0pgJlNAc4D4sF4OHBtNP8Q8MeiVpjA/PkhDN99\nN6xdC3vvHYZAHHUULF4cxgUPHw4bN8KmTcke99knXI5N1ygWkZZK0mOcpPH9BDDR3V8HcPdX812o\niIjsZACwPPb8ZWBk2jYLgA8RvvH7INDTzPZy99eAbmbWCGwDvuXuu4RmMxsHjAMYNGhQ3gpfvRru\nuScE4qeeCgH23HPhssvCFSQ6d87boUREWiRJME7S+B4MYGb/Igy3uMHd/5b+QoVqZEVEJKMvArea\n2eXAw8AKYHu0brC7rzCzA4AHzexpd38hvrO73w7cDlBTU+NtKeSdd+Avf4E774QZM8Il1d77Xpg4\nEerrw2XVRERKLV8n31UDw4A6YH/gYTM7wt3fiG+Uz0ZWRKSDWwEMjD3fP1r2LndfSegxxsx6ABek\n2mV3XxE9LjWzBuAYYKdg3FbuMG9e6BmePBnWrYP99gvDHC67LAyREBEpJ0mCcc7Gl9CL/Ji7bwX+\nY2aLCUF5bl6qFBGRdHOBYWY2lNAm1wM7nfRsZn2Bde6+g3AeyKRoeR9go7u/E21zIvCdfBd4xRXw\n619D167hdsyXXw6jRoWT5EREylGS5iln40s4oWMs8OuokT0YWJrPQkVEpIm7bzOzq4GZhCFsk9x9\noZndCDS6+3TCt3g3m5kThlJ8Otr9MODnZrYD6EQYY7xol4O00UUXwciR8JGPQO/e+X51EZH8yxmM\nEza+M4EzzWwRYfzal6KTO0REpEDcfQYwI23Z9bH5acC0DPs9AhxR6PrGjCn0EURE8ivRF1oJGl8n\nXBLoWkREREREKlCnUhcgIiIiIlIOFIxFRERERFAwFhEREREBFIxFRERERAAFYxERERERQMFYRERE\nRARQMBYRERERARSMRUREREQABWMREREREUDBWEREREQEUDAWEREREQEUjEVEREREAAVjERERERFA\nwVhEREREBFAwFhEREREBFIxFRERERAAFYxERERERQMFYRERERARQMBYRERERARSMRUREREQABWMR\nERERESBhMDazMWb2nJktMbPxGdZfbmZrzGx+NF2Z/1JFRERERAonZzA2sypgInA2MBwYa2bDM2x6\nr7sfHU2/zHOdIiKSJkGnxWAze8DMnjKzBjPbP7buMjN7PpouK27lIiLlKUmP8QhgibsvdfctwBTg\nvMKWJSIizUnYafE94C53PxK4Ebg52ndP4OvASEIb/3Uz61Os2kVEylWSYDwAWB57/nK0LN0FUa/E\nNDMbmJfqREQkmySdFsOBB6P5h2LrzwJmu/s6d38dmA2MKULNIiJlLV8n3/0ZGBL1SswG7sy0kZmN\nM7NGM2tcs2ZNng4tItIhJem0WAB8KJr/INDTzPZKuK/abBHpcJIE4xVAvAd4/2jZu9z9NXd/J3r6\nS+C4TC/k7re7e4271/Tr16819YqISHJfBE41syeBUwlt9/akO6vNFpGOJkkwngsMM7OhZtYFqAem\nxzcws/1iT88FnslfiSIikkGSTouV7v4hdz8G+Gq07I0k+4qIdEQ5g7G7bwOuBmYSAu9Ud19oZjea\n2bnRZp81s4VmtgD4LHB5oQoWEREgWadFXzNLtfPXAZOi+ZnAmWbWJzrp7sxomYhIh1adZCN3nwHM\nSFt2fWz+OkKjKyIiReDu28ws1WlRBUxKdVoAje4+HagDbjYzBx4GPh3tu87MJhDCNcCN7r6u6D+E\niEiZSRSMRUSk/CTotJgGTMuy7ySaepBFRATdElpEREREBFAwFhEREREBFIxFRERERAAFYxERERER\nQMFYRERERARQMBYRERERARSMRUREREQABWMREREREUDBWEREREQEUDAWEREREQEUjEVEREREAAVj\nERERERFAwVhEREREBFAwFhEREREBFIxFRERERAAFYxERERERQMFYRERERARQMBYRERERARSMRURE\nREQABWMREREREUDBWEREREQESBiMzWyMmT1nZkvMbHwz211gZm5mNfkrUURERESk8HIGYzOrAiYC\nZwPDgbFmNjzDdj2Ba4DH8l2kiIiIiEihJekxHgEscfel7r4FmAKcl2G7CcC3gc15rE9ERLLI9W2e\nmQ0ys4fM7Ekze8rMzomWDzGzTWY2P5p+VvzqRUTKT5JgPABYHnv+crTsXWZ2LDDQ3e9r7oXMbJyZ\nNZpZ45o1a1pc7PPPw7PPtng3EZF2J+G3eV8Dprr7MUA9cFts3QvufnQ0XVWUokVEylybT74zs07A\nD4Av5NrW3W939xp3r+nXr1+LjrN1K5x+OnzsY7BjRyuLFRFpP5J8m+dAr2h+D2BlEesTEak4SYLx\nCmBg7Pn+0bKUnsB7gAYzWwYcD0zP9wl4nTvDN78Jjz4Kt9+ez1cWEalIOb/NA24APmpmLwMzgM/E\n1g2Nhlj83cxOznSAtn7LJyJSaZIE47nAMDMbamZdCF/HTU+tdPf17t7X3Ye4+xDgUeBcd2/Md7GX\nXgqnnQbjx8Mrr+T71UVE2p2xwB3uvj9wDvB/0bd8q4BB0RCLa4F7zKxX+s5t+ZZPRKQS5QzG7r4N\nuBqYCTxDGK+20MxuNLNzC11gnBn89KewaRNce20xjywiUnZyfZsHcAUwFcDd5wDdgL7u/o67vxYt\nnwe8ABxc8IpFRMpcojHG7j7D3Q929wPd/ZvRsuvdfXqGbesK0Vuccsghocd48mSYNatQRxERKXvN\nfpsXeQk4A8DMDiME4zVm1i86eQ8zOwAYBiwtWuUiImWqIu98d911MGwYfOpTofdYRKSjSfht3heA\nT5jZAmAycLm7O3AK8JSZzQemAVe5+7ri/xQiIuWlutQFtEa3bnDbbTB6NNx0E0yYUOqKRESKz91n\nEE6qiy+7Pja/CDgxw36/A35X8AJFRCpMRfYYA4waBZdcAt/+NjzzTKmrEREREZFKV7HBGOD734fu\n3eG//xvcS12NiIiIiFSyig7G++wTeoz//ne4885SVyMiIiIilayigzHAlVfCCSfAF78Ia9eWuhoR\nERERqVQVH4w7dYKf/QzWr4cvf7nU1YiIiIhIpar4YAxwxBHhhh+//jU8/HCpqxERERGRStQugjHA\n9dfD4MFw1VWwZUupqxERERGRStNugnH37jBxYrh023e/W+pqRERERKTStJtgDPC+98EFF8A3vgEv\nvFDqakRERESkkrSrYAxwyy3QuXO4XbSubSwiIiIiSbW7YDxgAHzzmzBrFtx7b6mrEREREZFK0e6C\nMYTe4poa+Nzn4I03Sl2NiIiIiFSCdhmMq6rg5z+HNWvgK18pdTUiIiIiUgnaZTAGOPZY+Mxnws0/\nHnus1NWIiIiISLlrt8EYYMIE6N8fPvlJ2Lat1NWIiIiISDlr18G4Z0/48Y9hwYJwtQoRERERkWza\ndTAG+OAH4f3vD3fGW7iw1NWIiIiISLlq98HYLNwRb4894LTTFI5FREREJLN2H4wBBg2Chx6C6uoQ\njv/971JXJCIiIiLlJlEwNrMxZvacmS0xs/EZ1l9lZk+b2Xwz+6eZDc9/qW1zyCHQ0BDuinfaafD0\n06WuSERERETKSc5gbGZVwETgbGA4MDZD8L3H3Y9w96OB7wA/yHuleXDwwSEcd+0Kp58OTz1V6opE\nREREpFwk6TEeASxx96XuvgWYApwX38Dd34w97Q54/krMr2HDdg7HCxaUuiIRERERKQdJgvEAYHns\n+cvRsp2Y2afN7AVCj/FnM72QmY0zs0Yza1yzZk1r6s2Lgw4K4Xi33eCMMxSORURERCSPJ9+5+0R3\nPxD4f8DXsmxzu7vXuHtNv3798nXoVkmF4913Dz3H8+eXtBwRkRZLcP7HIDN7yMyeNLOnzOyc2Lrr\nov2eM7Ozilu5iEh5ShKMVwADY8/3j5ZlMwU4vy1FFcuBB4Zw3L176Dl+8slSVyQikkzC8z++Bkx1\n92OAeuC2aN/h0fPDgTHAbdHriYh0aEmC8VxgmJkNNbMuhMZ0enwDMxsWe/o+4Pn8ldh2c+bAzTeH\nx3QHHBDCcY8eIRw/8UTRyxMRaY2c538QzvfoFc3vAayM5s8Dprj7O+7+H2BJ9HoiIh1ada4N3H2b\nmV0NzASqgEnuvtDMbgQa3X06cLWZjQK2Aq8DlxWy6JaYMycE3i1boEsXeOABqK3deZtUOD7tNBg1\nCu6/H449tiTliogklen8j5Fp29wAzDKzzxBOjB4V2/fRtH13OXdERKSjSTTG2N1nuPvB7n6gu38z\nWnZ9FIpx92vc/XB3P9rdT3P3srm/XENDCMXbt4fHhobM2w0dGtb16hWC9Lx5RSxSRKQwxgJ3uPv+\nwDnA/5lZ4nNLyuWEaRGRYmn3d76rqws9xVVV4bGuLvu2Q4aEcNy7d+g5bmwsTo0iIq2Q5PyPK4Cp\nAO4+B+gG9E24b1mdMC0iUgztPhjX1obhExMmZB5GkS4Vjvv0CeF47txiVCki0mI5z/8AXgLOADCz\nwwjBeE20Xb2ZdTWzocAw4PGiVS4iUqZyjjFuD2prcwfiuMGDQziuq4PRo2HWLBih01JEpIwkPP/j\nC8AvzOzzhBPxLnd3Bxaa2VRgEbAN+LS7by/NTyIiUj4stJHFV1NT441lPlbhpZfCCXlvvhku5bb/\n/qWuSETKgZnNc/eaUtdRTJXQZouIZJO03W73QynaYtAguO8+2LwZLroonLwnIiIiIu2TgnEOhx4K\nkyaFy759+culrkZERERECkXBOIELL4RrroFbboF77y11NSIiIiJSCArGCX3nO3DCCXDllfDss6Wu\nRkRERETyTcE4oS5dYOpU2G03uOACeOutUlckIiIiIvmkYNwCAwbA5Mmhx3jcOCjRBT1EREREpAAU\njHOYMwduvjk8Qrhd9IQJISDfdltpaxMRERGR/OkQN/horTlzQhDesiUMpUjdOW/8+LDu85+HmhoY\nObLUlYqIiIhIW6nHuBkNDSEUb98eHhsawvJOneCuu8LQigsvhLVrS1mliIiIiOSDgnEz6upCT3FV\nVXisq2ta16cP/O538OqrcMklITyLiIiISOVSMG5GbW0YPjFhQtMwirhjj4Wf/ARmzQrbiIiIiEjl\n0hjjHGprdw3EcVdeCY88AjeLPJG/AAAS+klEQVTeCMcfD2PGFK82EREREckf9Ri3kRlMnAhHHBGG\nVLz4YqkrEhEREZHWUDDOg913D+ONt20LJ+O9806pKxIRERGRllIwzpODDoI774S5c8Nl3ERERESk\nsigY59H558OXvgQ//SncfXepqxERERGRllAwzrObboJTTgm3jP73v0tdjYiIiIgklSgYm9kYM3vO\nzJaY2fgM6681s0Vm9pSZPWBmg/NfamWoroZ774VeveCCC2D9+lJXJCIiIiJJ5AzGZlYFTATOBoYD\nY81seNpmTwI17n4kMA34Tr4LrST77hvC8dKlcPbZCsciIiIilSBJj/EIYIm7L3X3LcAU4Lz4Bu7+\nkLtvjJ4+Cuyf3zIrzymnwNSp4WS8s85SOBYREREpd0mC8QBgeez5y9GybK4A/ppphZmNM7NGM2tc\ns2ZN8ior1L77Qn09zJsHo0fD66+XuiIRERERySavJ9+Z2UeBGuC7mda7++3uXuPuNf369cvnocvO\nnDlwxhkweTJ06gTz58OoUbBuXakrExEREZFMkgTjFcDA2PP9o2U7MbNRwFeBc929w9/ioqEBtmyB\n7dvDdPHFsHBhCMuvvVbq6kREREQkXZJgPBcYZmZDzawLUA9Mj29gZscAPyeE4lfzX2blqauDLl2g\nqio8fvKT8Kc/wTPPhHC8dm2pKxQRERGRuJzB2N23AVcDM4FngKnuvtDMbjSzc6PNvgv0AH5rZvPN\nbHqWl+swamvhgQdgwoTwWFsbTsL785/huefg9NPhVf0JISJtkOBSmj+M2uT5ZrbYzN6IrdseW9fh\n22wREQBz95IcuKamxhsbG0ty7FJ78EF4//th6NAwv88+pa5IRFrCzOa5e02Ja6gCFgOjCSdFzwXG\nuvuiLNt/BjjG3T8ePX/L3XskPV5HbrNFpPIlbbd157sSOP10mDEDli2D006DV14pdUUiUoFyXkoz\nzVhgclEqExGpUArGJVJXB3/9K7z0UphfubLUFYlIhUl8Kc3obqRDgQdji7tFl8981MzOz7Jfh7rE\npoiIgnEJnXIK/O1vsGJFCMcrdrnWh4hIXtQD09x9e2zZ4OhrxYuBH5nZgek7daRLbIqIgIJxyZ10\nEsycGYZTnHoqLF+eex8RERJeSjNST9owCndfET0uBRqAY/JfoohIZVEwLgMnnACzZsGaNaHn+KWX\nSl2RiFSAnJfSBDCzQ4E+wJzYsj5m1jWa7wucCGQ8aU9EpCNRMC4Txx8Ps2eHm3+cemo4MU9EJJuE\nl9KEEJin+M6XIDoMaDSzBcBDwLeyXc1CRKQjqS51AdJkxIhwzePRo0NQvuUWuOgiMCt1ZSJSjtx9\nBjAjbdn1ac9vyLDfI8ARBS1ORKQCqce4zBx3HPz4x1BdDfX14aYgzz9f6qpERERE2j8F4zIzZw6M\nGwerVkHnzvDII3DEEXDDDbB5c6mrExEREWm/FIzLTEMDbNkCO3aE6bOfhQsugP/93xCQZ80qdYUi\nIiIi7ZOCcZmpq4MuXaCqKjx+4ANw991w//3QqVMYWvGRj+iGICIiIiL5pmBcZmprwwl4EyaEx9ra\nsPyMM+Cpp+DGG+FPf4JDDw0n523bVtp6RURERNoLBeMyVFsL113XFIpTunaF//kfWLgQTjwRPve5\ncCWLxx4rTZ0iIiIi7YmCcQU68ECYMQN++1tYvToE6KuugtdfL3VlIiIiIpVLwbhCmcGHPwzPPht6\njn/xCzjkELjrLtjpMv4iIiIikoiCcYXr2RN+8AOYNy/0JF92GRx1FEyapMu7iYiIiLSEgnE7cfTR\n8K9/hTHIa9bAFVfA4MHh+serV5e6OhEREZHyp2Dcjjz2GHzve/Dqq+FSbwcdFK5/PGhQCMpPP13q\nCkVERETKl4JxOxK/Ocj27fD+94cxyFdcAZMnw5FHwujR4cS9HTtKXa2IiIhIeVEwbkfSbw5SVxdO\nyLvtNli+HG66CRYtgve9Dw4/HH7+c9i4sdRVi4iIiJQHBeN2JNvNQQD22itcG/k//4Hf/Aa6dw+X\neBs0CL76Vd1JT0RERCRRMDazMWb2nJktMbPxGdafYmZPmNk2M/tw/suUpLLdHCSlSxe45BKYOxce\nfhhOPhluvhmGDAnL//IXeOedopYsIiIiUhZyBmMzqwImAmcDw4GxZjY8bbOXgMuBe/JdoBSGWQjF\nf/gDPP88nH8+/P738IEPwN57w6WXhltP65JvIiIi0lEk6TEeASxx96XuvgWYApwX38Ddl7n7U4BO\n6apAr74aeoq3bAk9yiefDPfdF8Jyv35w8cUhQG/aVOpKRURERAonSTAeACyPPX85WtZiZjbOzBrN\nrHHNmjWteQkpgPSrWZx4Yrj28d/+BvX1MGsWfOhDISTX18O0aTppT0RERNqfop585+63u3uNu9f0\n69evmIeWZmS6mkXnznDWWeFW06tWwezZ8NGPwoMPwoUXhpB84YUwdSq89VapfwIRERGRtqtOsM0K\nYGDs+f7RMmknUlezaGgIoTj9xL3OnWHUqDDdeiv84x/w29+GMcnTpsFuu8Fxx8HBB+88HXggdOtW\nip9IREREpOWSBOO5wDAzG0oIxPXAxQWtSoqutjb7lSziqqvhtNPC9JOfwD//CRMnhqtcLFoE69Y1\nbWsWrnaRHpgPPhgGDgw91CIiIiLlImcwdvdtZnY1MBOoAia5+0IzuxFodPfpZvZe4A9AH+ADZva/\n7n54QSuXkksNvYifuDdrFvTpA4sX7zz96187D7no2hWGDQu9yvvsA337Zp769QvXXDYr3c8pIiIi\nHUOSHmPcfQYwI23Z9bH5uYQhFtLBpE7c2749PDY2huso19TsvJ07vPLKroF5yRJ49FFYuza8RiZd\nu2YOzf37hx7poUPD4777KkCLiIhI6yUKxiLZpE7cS/UY19Vl3s4M9tsvTKeeGpbNmdM0rnnkSHjz\nzRCQ16wJj9mmJ58M27z++s7H6NYtBOR4WI4/7rWXgrO0L2Y2BriF8G3eL939W2nrfwicFj3dHdjb\n3XtH6y4Dvhat+4a731mcqkVEypeCsbRJrhP3spkzB844oylQp25h3bs3HHRQstfYuBGWLQu3uU5/\nfPzxncc7A/To0RScBwwIU//+Oz/uuafCs1SG2M2XRhMuoznXzKa7+6LUNu7++dj2nwGOieb3BL4O\n1AAOzIv2TftzU0SkY1EwljZLeuJeXPoQjIaGlr1GvLf5fe/LvM369SEoZwrPqeEb6bp2DSE5PTCn\nHvv2DWOeu3eH3XcPV+ToVNSLHoq8692bLwGYWermS4uybD+WEIYBzgJmu/u6aN/ZwBhgckErFhEp\ncwrGUhJJh2Bkkq23Od0ee8BRR4Upk3feCddoXrECVq7c9XH+/HAHwLffbr6e3XYLITkVluPz6ct6\n9GgK1knmu3RJ/r5Ih5Pp5ksjM21oZoOBocCDzey7y42bzGwcMA5g0KBBba9YRKTMKRhLSbR2CAbk\nt7e5tjYMrcjGHTZsaArLa9eGIRyp6e23d51PPb7xRtgvtSw1uSevtXPnnUN2S+e7dQu94F27hpCd\nmk+fUuu6dNFQknaqHpjm7llOcc3M3W8Hbgeoqalpwb9cEZHKpGAsJdOaIRhQnN7mFDPo1StMb7wB\nS5e2PMjHucPmzeHSdamgnGQ+NaVC9oYN4bbd6et37GhdXXGpkFxdHYJ5dfXO87mWdevW1Eue6k2P\nT5mWpZanwnl8qq5WWM+iJTdfqgc+nbZvXdq+DXmsTUSkIikYS8UpRW9zSwN1pv3j9e62W7hGcz65\nh/riAXrz5jBkJDVt2bLz8+bWbdvWNG3d2vz81q3hmFu3hn03bdq5Z33r1rb9bOlhOVN4rqrKPHXq\nlH1dVRVcdRWccEJ+PoMiS3TzJTM7lHCN+TmxxTOBm8ysT/T8TOC6wpYrIlL+FIylIhW7t7ktwzfa\nEqrTA3VzzJqGRuy5Z7LXL5atW3cNy+nPN24M71Frpq1bw2cTn1Kf144du66LTxdcUOp3p3WS3Hwp\n2rQemOLeNIjH3deZ2QRCuAa4MXUinohIR6ZgLB1Ka3ub2zJ8o1x6qQu9X3M6dw5Tr175eT0Jct18\nKXp+Q5Z9JwGTClaciEgFUjCWDqc1vc1tGb5RSb3U7SmMi4iItJSCsUhCrR2+UUm91B0pjLd1X8lN\n76+IVBoFY5EiqJRe6o4Sxtu6r+Sm91dEKpGCsUgZK3YvdUcJ423dV3LT+ysilUjBWKSdakuobu9h\nvK37Sm56f0WkEpm35DZceVRTU+ONjY0lObaItB+lGGNsZvPcvaZlR6tsrWmzNcZYRMpF0nZbPcYi\nUtFa28Pd1n0lN72/IlJpOpW6ABERERGRcqBgLCIiIiKCgrGIiIiICKBgLCIiIiICKBiLiIiIiAAK\nxiIiIiIiQAmvY2xma4AXW7FrX2Btnstpi3KrB8qvpnKrB8qvJtWTWznVNNjd+5W6iGJqR202lF9N\nqie3cqup3OqB8qup3OpJ1G6XLBi3lpk1ltOF9cutHii/msqtHii/mlRPbuVYk+RWjp9budWkenIr\nt5rKrR4ov5rKrZ6kNJRCRERERAQFYxERERERoDKD8e2lLiBNudUD5VdTudUD5VeT6smtHGuS3Mrx\ncyu3mlRPbuVWU7nVA+VXU7nVk0jFjTEWERERESmESuwxFhERERHJOwVjERERERHKOBib2Rgze87M\nlpjZ+Azru5rZvdH6x8xsSAFrGWhmD5nZIjNbaGbXZNimzszWm9n8aLq+UPXEjrnMzJ6OjteYYb2Z\n2Y+j9+gpMzu2gLUcEvvZ55vZm2b2ubRtCv4emdkkM3vVzP4dW7anmc02s+ejxz5Z9r0s2uZ5M7us\ngPV818yejT6TP5hZ7yz7Nvv55rGeG8xsRexzOSfLvs3+n8xzTffG6llmZvOz7Jv390haR212orrU\nZu9ah9rs1tVUsna73bfZ7l52E1AFvAAcAHQBFgDD07b5FPCzaL4euLeA9ewHHBvN9wQWZ6inDvhL\nkd+nZUDfZtafA/wVMOB44LEifn6vEC6mXdT3CDgFOBb4d2zZd4Dx0fx44NsZ9tsTWBo99onm+xSo\nnjOB6mj+25nqSfL55rGeG4AvJvhMm/0/mc+a0tZ/H7i+WO+RplZ9hmqzk9WlNnvXY6vNbl1NJWu3\n23ubXa49xiOAJe6+1N23AFOA89K2OQ+4M5qfBpxhZlaIYtx9lbs/Ec1vAJ4BBhTiWHl2HnCXB48C\nvc1svyIc9wzgBXdvzV2y2sTdHwbWpS2O/1u5Ezg/w65nAbPdfZ27vw7MBsYUoh53n+Xu26KnjwL7\nt/U4baknoST/J/NeU/R/+iJgcj6OJQWjNjs/1GYHarNz1JRQQdrt9t5ml2swHgAsjz1/mV0btXe3\nif7Brgf2KnRh0dd/xwCPZVhda2YLzOyvZnZ4oWsBHJhlZvPMbFyG9Unex0KoJ/t/imK/RwD7uPuq\naP4VYJ8M25Tqvfo4oYcok1yfbz5dHX1NOCnL15alen9OBla7+/NZ1hfzPZLs1GYnozY7GbXZyZRj\nu13xbXa5BuOyZGY9gN8Bn3P3N9NWP0H4Guoo4CfAH4tQ0knufixwNvBpMzulCMdslpl1Ac4Ffpth\ndSneo514+C6nLK5RaGZfBbYBd2fZpFif70+BA4GjgVWEr8HKxVia73kou/8DUj7UZuemNju5Mmqz\noXzb7Ypvs8s1GK8ABsae7x8ty7iNmVUDewCvFaogM+tMaGDvdvffp6939zfd/a1ofgbQ2cz6Fqqe\n6DgrosdXgT8QvjaJS/I+5tvZwBPuvjp9RSneo8jq1NeR0eOrGbYp6ntlZpcD7wcuiRr+XST4fPPC\n3Ve7+3Z33wH8Istxiv5vKfp//SHg3mzbFOs9kpzUZiegNjsxtdk5lGO73V7a7HINxnOBYWY2NPpr\nth6YnrbNdCB1FuqHgQez/WNtq2jMzK+AZ9z9B1m22Tc1Xs7MRhDe20I2+t3NrGdqnnBywL/TNpsO\n/JcFxwPrY19PFUrWvxaL/R7FxP+tXAb8KcM2M4EzzaxP9JXUmdGyvDOzMcCXgXPdfWOWbZJ8vvmq\nJz6G8YNZjpPk/2S+jQKedfeXM60s5nskOanNzl2T2uzk1Gbnrqkc2+320WYnPUuv2BPh7NzFhDMq\nvxotu5HwDxOgG+GrnyXA48ABBazlJMJXOU8B86PpHOAq4Kpom6uBhYSzPh8FTijw+3NAdKwF0XFT\n71G8JgMmRu/h00BNgWvqTmg094gtK+p7RGjgVwFbCeOpriCMY3wAeB64H9gz2rYG+GVs349H/56W\nAB8rYD1LCOO+Uv+WUmfq9wdmNPf5Fqie/4v+fTxFaDT3S68ner7L/8lC1RQtvyP1bye2bcHfI02t\n/hzVZjdfk9rszDWozW5dTSVrtzPVEy2/g3bQZuuW0CIiIiIilO9QChERERGRolIwFhERERFBwVhE\nREREBFAwFhEREREBFIxFRERERAAFYxERERERQMFYRERERASA/w8sEmoKMn9H5gAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvsLH3wYDhY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_iob(wids):\n",
        "  \n",
        "  global model\n",
        "  \n",
        "  if type(wids) is list:\n",
        "    word_ids = np.array(wids)\n",
        "  else:\n",
        "    word_ids = wids\n",
        "\n",
        "  iobs = model.predict(word_ids.reshape(1, -1), batch_size=1).reshape(-1, 3)\n",
        "  iobs = np.argmax(iobs[:len(wids)], axis=-1)\n",
        "\n",
        "  return iobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj3wSVIVrsRo",
        "colab_type": "text"
      },
      "source": [
        "## Simple Entity Disambiguator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxL0MPA1YA87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_disamb(mention, word2id, wid2wikiids, epsilon=0.001):\n",
        "    \n",
        "  candidates = {}\n",
        "  \n",
        "  if type(mention) is str:\n",
        "    mention_words = list(filter(lambda w: w in word2id, split_name(mention)))\n",
        "    mention_ids = list(map(lambda w: word2id[w], mention_words))\n",
        "\n",
        "  elif type(mention) is list and type(mention[0]) is str:\n",
        "    mention_ids = list(map(lambda w: word2id[w], mention))\n",
        "    \n",
        "  else:\n",
        "    mention_ids = mention\n",
        "  \n",
        "  for wid in mention_ids:\n",
        "    if wid not in wid2wikiids:\n",
        "      continue\n",
        "    for wikiid, score in wid2wikiids[wid].items():\n",
        "      if wikiid in candidates:\n",
        "        candidates[wikiid][wid] = score\n",
        "      else:\n",
        "        candidates[wikiid] = {wid: score}\n",
        "  \n",
        "  scores = {}\n",
        "  \n",
        "  for wikiid, word_scores in candidates.items():\n",
        "    score = 0\n",
        "    for wid, sc in word_scores.items():\n",
        "      score += sc\n",
        "    scores[wikiid] = score\n",
        "    \n",
        "  \n",
        "  max_score, best_candidate = 0, -1   # unk entity id\n",
        "  for cand, score in scores.items():\n",
        "    if score > max_score:\n",
        "      max_score = score\n",
        "      best_candidate = cand\n",
        "      \n",
        "  return best_candidate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAMzAP2onqWh",
        "colab_type": "code",
        "outputId": "173def5d-a2a9-42e0-e529-267d1a3f5e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wikiid2name[baseline_disamb('Barcelona', word2id, wid2wikiids)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FC Barcelona'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP-Rg4zl5tPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def disamb_tagged_doc(wids, iobs):\n",
        "  \n",
        "  best = {}\n",
        "  \n",
        "  start, end = -1, -1\n",
        "  \n",
        "  for idx, tag in enumerate(iobs):\n",
        "    if tag in [0, 1] and start >= 0:\n",
        "      best[f'{start}:{end}'] = baseline_disamb(wids[start:end+1], word2id, wid2wikiids)\n",
        "      start, end = -1, -1\n",
        "      \n",
        "    if tag == 1:    # iob_b\n",
        "      start, end = idx, idx\n",
        "      \n",
        "    if tag == 2:\n",
        "      end = idx\n",
        "      \n",
        "  if start >= 0:\n",
        "    best[f'{start}:{end}'] = baseline_disamb(wids[start:end+1], word2id, wid2wikiids)\n",
        "      \n",
        "  return best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CCaZvFq-HFR",
        "colab_type": "text"
      },
      "source": [
        "# 3. Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeJ3CEtLkxSg",
        "colab_type": "text"
      },
      "source": [
        "## Load Saved Mention Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8a31JJTpf75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "\n",
        "if not os.path.exists('md_model.h5'):\n",
        "  ! cp drive/My\\ Drive/e2e_el/md_model.h5 md_model.h5\n",
        "\n",
        "model = load_model('md_model.h5', custom_objects={'f1': f1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he99KsvOk5ZH",
        "colab_type": "text"
      },
      "source": [
        "## Test Model With Arbitary Input Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q54kWy_lZZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_entity_names(text, human_readable=True):\n",
        "  \n",
        "  clean = [w for w in text.split(' ') if w in word2id]\n",
        "  word_ids = np.array([word2id[w] for w in clean])\n",
        "  \n",
        "  iobs = predict_iob(word_ids)\n",
        "  disambiguated = disamb_tagged_doc(word_ids, iobs)\n",
        "\n",
        "  if not human_readable:\n",
        "    return disambiguated\n",
        "  \n",
        "  human_readable = {}\n",
        "  \n",
        "  for boundary, wikiid in disambiguated.items():\n",
        "    start, end = tuple(map(int, boundary.split(':')))\n",
        "    mention = ' '.join([f'[{boundary:5s}]'] + clean[start:end+1])\n",
        "    human_readable[mention] = wikiid2name[wikiid]\n",
        "  \n",
        "  return human_readable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGHLtvcMmI4f",
        "colab_type": "code",
        "outputId": "90dc53ad-8d53-4aba-aa7e-80429f9ff17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from_testa = 'They were held up by a gritty 84 from Paul Johnson but ex-England fast bowler Martin McCague took four for 55 .'\n",
        "politics = sentence = 'President Barack Obama last week said he will impose a blanket tariff on Mexican imports from June 10 to try to pressure Mexico to tackle large flows of mostly Central American migrants passing through en route to the United States'\n",
        "sports = 'Barcelona plays with Sevilla'\n",
        "\n",
        "text_to_entity_names(politics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[13:13] Mexican': 'Mexico',\n",
              " '[1:2  ] Barack Obama': 'Barack Obama',\n",
              " '[22:22] Mexico': 'Mexico',\n",
              " '[29:30] Central American': 'United States',\n",
              " '[38:39] United States': 'United States'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJwnTSslIo1",
        "colab_type": "text"
      },
      "source": [
        "## Functions to evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MPfcRO08Eeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_correct(predicted, gold, strong_match=True, return_totals=True):\n",
        "  \n",
        "  total_pred, total_gold = len(predicted), len(gold)\n",
        "  correct = 0\n",
        "  \n",
        "  if strong_match:\n",
        "    for b in predicted.keys():\n",
        "      if b in gold and predicted[b] == gold[b]:\n",
        "        correct += 1\n",
        "  else:\n",
        "    for b, e in gold.items():\n",
        "      for pb, pe in predicted.items():\n",
        "        if pe == e:\n",
        "          g_start, g_end = int(b.split(':')[0]), int(b.split(':')[1])\n",
        "          p_start, p_end = int(pb.split(':')[0]), int(pb.split(':')[1])\n",
        "          if p_start in range(g_start, g_end+1) or p_end in range(g_start, g_end+1):\n",
        "            correct += 1\n",
        "\n",
        "  if return_totals:\n",
        "    return correct, total_pred, total_gold\n",
        "  else:\n",
        "    return correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yakmAuuyzNLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from commons import show_progress\n",
        "\n",
        "def calculate_micro_f1(aida_path='aida-testa.tsv', total_docs=216, strong_match=True):\n",
        "  \n",
        "  total_pred = 0       # number of entities in predictions\n",
        "  total_gold = 0       # number of gold entities in test set\n",
        "  correct = 0          # number of predicted entities that match entity\n",
        "                       # and boundary (in strong match)\n",
        "  doc_idx = 0\n",
        "\n",
        "  for wids, golds in process_aida.gen_doc_with_golds(aida_path, word2id):\n",
        "\n",
        "    show_progress(percent=doc_idx/total_docs)\n",
        "    \n",
        "    iobs = predict_iob(wids)\n",
        "    predicted = disamb_tagged_doc(wids, iobs)\n",
        "    corr, tot_pred, tot_gold = count_correct(predicted, golds,\n",
        "                                            strong_match=strong_match)\n",
        "    total_pred += tot_pred\n",
        "    correct += corr\n",
        "    total_gold += tot_gold\n",
        "    \n",
        "    doc_idx += 1\n",
        "  \n",
        "  show_progress(percent=1.0, done=True)\n",
        "  \n",
        "  precision, recall = correct/total_pred, correct/total_gold\n",
        "  f_score = (2 * precision * recall) / (precision + recall)\n",
        "  \n",
        "  return precision, recall, f_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFxIFuWBj8lX",
        "colab_type": "text"
      },
      "source": [
        "## Micro F1 Scores for Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhly7f1Ojhz8",
        "colab_type": "code",
        "outputId": "6941bdde-5b34-4e29-8c08-36fd135e55e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "precision, recall, f_score = calculate_micro_f1(strong_match=False)\n",
        "print(f'evaluation on aida validation set with weak matching:')\n",
        "print(f'precision: {precision:.3f}\\nrecall:    {recall:.3f}\\nf1-score:  {f_score:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===================================================] 100% done!\n",
            "evaluation on aida validation set with weak matching:\n",
            "precision: 0.556\n",
            "recall:    0.728\n",
            "f1-score:  0.631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkWjaH6FkC_N",
        "colab_type": "code",
        "outputId": "af9414c2-e3b5-4b6c-edca-f7939d22858a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "precision, recall, f_score = calculate_micro_f1(strong_match=True)\n",
        "print(f'evaluation on aida validation set with strong matching:')\n",
        "print(f'precision: {precision:.3f}\\nrecall:    {recall:.3f}\\nf1-score:  {f_score:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===================================================] 100% done!\n",
            "evaluation on aida validation set with strong matching:\n",
            "precision: 0.524\n",
            "recall:    0.686\n",
            "f1-score:  0.594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0qBtwzjjn0L",
        "colab_type": "code",
        "outputId": "579cb5d9-ae17-4724-c552-413abdea35fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "precision, recall, f_score = calculate_micro_f1(aida_path='aida-testb.tsv',\n",
        "                                                strong_match=False)\n",
        "print(f'evaluation on aida test set with weak matching:')\n",
        "print(f'precision: {precision:.3f}\\nrecall:    {recall:.3f}\\nf1-score:  {f_score:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===================================================] 100% done!\n",
            "evaluation on aida test set with weak matching:\n",
            "precision: 0.448\n",
            "recall:    0.619\n",
            "f1-score:  0.520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkqU-RWbjoXR",
        "colab_type": "code",
        "outputId": "fef8ea8d-6858-4e77-f72b-9531a8590701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "precision, recall, f_score = calculate_micro_f1(aida_path='aida-testb.tsv',\n",
        "                                                strong_match=True)\n",
        "print(f'evaluation on aida test set with strong matching:')\n",
        "print(f'precision: {precision:.3f}\\nrecall:    {recall:.3f}\\nf1-score:  {f_score:.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===================================================] 100% done!\n",
            "evaluation on aida test set with strong matching:\n",
            "precision: 0.415\n",
            "recall:    0.573\n",
            "f1-score:  0.481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQbEnly9BsXV",
        "colab_type": "text"
      },
      "source": [
        "# 4. Extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsw_c2XRi0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "ram = 0\n",
        "\n",
        "for var, obj in locals().items():\n",
        "  if sys.getsizeof(obj) > 10**6:\n",
        "    print(f'{var:16s}: {sys.getsizeof(obj) / 10**6}')\n",
        "  ram += sys.getsizeof(obj)\n",
        "\n",
        "print(f'used ram: {ram / 10**6}')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}